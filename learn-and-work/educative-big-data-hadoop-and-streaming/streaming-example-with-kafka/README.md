## A Streaming Example

#### How to run:

1. Start kafka cluster
```bash
docker-compose up -d
```

2.  Start the producer
```bash
python3 producer.py
```

3. Start the consumer (in a new terminal tab)
```bash
python3 consumer.py
```

#### Output analyzed
We can see that the consumerâ€™s output is coming up only when we have an odd random number generated by the consumer.

Here is sample output from the consumer:

```log
ConsumerRecord(topic='surprise_me', partition=0, offset=980, timestamp=1592850248633, timestamp_type=0, key=None, value=b'658', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=3, serialized_header_size=-1)
```
The most important things from the code above are:

- The topic it was read from.
- The offset of the message.
- The timestamp of the write from the producer.
- The value in bytes.
